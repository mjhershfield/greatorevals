{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GatorEvals Public Dataset!\n"
     ]
    }
   ],
   "source": [
    "from tableauscraper import TableauScraper as TS\n",
    "\n",
    "url = \"https://public.tableau.com/views/GatorEvalsFall2019toFall2021PublicData/GatorEvalsPublic\"\n",
    "\n",
    "ts = TS()\n",
    "ts.loads(url)\n",
    "workbook = ts.getWorkbook()\n",
    "\n",
    "worksheet = workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "data = worksheet.data\n",
    "head = data.head()\n",
    "\n",
    "print(\"Loaded GatorEvals Public Dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTER OPTIONS:\n",
      "---------------\n",
      "COLLEGE\n",
      "COMBINED_COURSE\n",
      "DEPARTMENT\n",
      "INSTRUCTOR_NAME\n",
      "Term\n"
     ]
    }
   ],
   "source": [
    "all_filters = worksheet.getFilters()\n",
    "college_options = all_filters[0][\"values\"]\n",
    "course_options = all_filters[1][\"values\"]\n",
    "department_options = all_filters[2][\"values\"]\n",
    "instructor_options = all_filters[3][\"values\"]\n",
    "term_options = all_filters[4][\"values\"]\n",
    "print(\"FILTER OPTIONS:\")\n",
    "print(\"---------------\")\n",
    "for f in all_filters:\n",
    "    print(f[\"column\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress through courses in AGL(AG)-Agricultural & BiolEng:   0%|          | 0/44 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/matthew/projects/gator-evals-scraper/scraper.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/matthew/projects/gator-evals-scraper/scraper.ipynb#ch0000003vscode-remote?line=34'>35</a>\u001b[0m workbook \u001b[39m=\u001b[39m ts\u001b[39m.\u001b[39mgetWorkbook()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/matthew/projects/gator-evals-scraper/scraper.ipynb#ch0000003vscode-remote?line=35'>36</a>\u001b[0m worksheet \u001b[39m=\u001b[39m workbook\u001b[39m.\u001b[39mgetWorksheet(\u001b[39m\"\u001b[39m\u001b[39mGatorEvals Public Data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/matthew/projects/gator-evals-scraper/scraper.ipynb#ch0000003vscode-remote?line=37'>38</a>\u001b[0m filtered_workbook \u001b[39m=\u001b[39m worksheet\u001b[39m.\u001b[39;49msetFilter(\u001b[39m\"\u001b[39;49m\u001b[39mDEPARTMENT\u001b[39;49m\u001b[39m\"\u001b[39;49m, department)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/matthew/projects/gator-evals-scraper/scraper.ipynb#ch0000003vscode-remote?line=38'>39</a>\u001b[0m filtered_worksheet \u001b[39m=\u001b[39m filtered_workbook\u001b[39m.\u001b[39mgetWorksheet(\u001b[39m\"\u001b[39m\u001b[39mGatorEvals Public Data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/matthew/projects/gator-evals-scraper/scraper.ipynb#ch0000003vscode-remote?line=39'>40</a>\u001b[0m filtered_workbook \u001b[39m=\u001b[39m filtered_worksheet\u001b[39m.\u001b[39msetFilter(\u001b[39m\"\u001b[39m\u001b[39mCOMBINED_COURSE\u001b[39m\u001b[39m\"\u001b[39m, course)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tableauscraper/TableauWorksheet.py:183\u001b[0m, in \u001b[0;36mTableauWorksheet.setFilter\u001b[0;34m(self, columnName, value, dashboardFilter, membershipTarget, filterDelta, indexValues)\u001b[0m\n\u001b[1;32m    180\u001b[0m     r \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mdashboardFilter(\n\u001b[1;32m    181\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scraper, columnName, [value] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mlist\u001b[39m) \u001b[39melse\u001b[39;00m value)\n\u001b[1;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     r \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39;49mfilter(\n\u001b[1;32m    184\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_scraper,\n\u001b[1;32m    185\u001b[0m         worksheetName\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    186\u001b[0m         globalFieldName\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mglobalFieldName\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    187\u001b[0m         selection\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mindices\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    188\u001b[0m         selectionToRemove\u001b[39m=\u001b[39;49m[] \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m filterDelta \u001b[39melse\u001b[39;49;00m selectedIndex,\n\u001b[1;32m    189\u001b[0m         membershipTarget\u001b[39m=\u001b[39;49mmembershipTarget,\n\u001b[1;32m    190\u001b[0m         filterDelta\u001b[39m=\u001b[39;49mfilterDelta,\n\u001b[1;32m    191\u001b[0m         storyboard\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mstoryboard\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    192\u001b[0m         storyboardId\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mstoryboardId\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    193\u001b[0m         dashboard\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mdashboard\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdateFullData(r)\n\u001b[1;32m    196\u001b[0m \u001b[39mreturn\u001b[39;00m dashboard\u001b[39m.\u001b[39mgetWorksheetsCmdResponse(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scraper, r)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tableauscraper/api.py:149\u001b[0m, in \u001b[0;36mfilter\u001b[0;34m(scraper, worksheetName, globalFieldName, dashboard, selection, selectionToRemove, membershipTarget, filterDelta, storyboard, storyboardId)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfilter\u001b[39m(scraper, worksheetName, globalFieldName, dashboard, selection\u001b[39m=\u001b[39m[], selectionToRemove\u001b[39m=\u001b[39m[], membershipTarget\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, filterDelta\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, storyboard\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, storyboardId\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 149\u001b[0m     delayExecution(scraper)\n\u001b[1;32m    150\u001b[0m     visualIdPresModel \u001b[39m=\u001b[39m {\n\u001b[1;32m    151\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mworksheet\u001b[39m\u001b[39m\"\u001b[39m: worksheetName,\n\u001b[1;32m    152\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdashboard\u001b[39m\u001b[39m\"\u001b[39m: dashboard\n\u001b[1;32m    153\u001b[0m     }\n\u001b[1;32m    154\u001b[0m     \u001b[39mif\u001b[39;00m storyboard \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tableauscraper/api.py:349\u001b[0m, in \u001b[0;36mdelayExecution\u001b[0;34m(scraper)\u001b[0m\n\u001b[1;32m    347\u001b[0m     waitTime \u001b[39m=\u001b[39m timeDif \u001b[39m+\u001b[39m (scraper\u001b[39m.\u001b[39mdelayMs \u001b[39m/\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[1;32m    348\u001b[0m     scraper\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdelaying request by \u001b[39m\u001b[39m{\u001b[39;00mwaitTime\u001b[39m}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 349\u001b[0m     time\u001b[39m.\u001b[39;49msleep(waitTime)\n\u001b[1;32m    350\u001b[0m     scraper\u001b[39m.\u001b[39mlastActionTime \u001b[39m=\u001b[39m currentTime\n\u001b[1;32m    351\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Takes about 30 hours to run ðŸ˜¬\n",
    "\n",
    "overall_columns = [\"course_num\", \"professor\", \"term\", \"question_num\", \"rating\", \"percentage\"]\n",
    "overall_dataset = pd.DataFrame(columns=overall_columns)\n",
    "\n",
    "question_texts = data[\"University Core Questions-value\"].truncate(0, 9).to_list()\n",
    "question_dict = {}\n",
    "for i in range(0, len(question_texts)):\n",
    "    question_dict[question_texts[i]] = i\n",
    "\n",
    "professor_list = []\n",
    "\n",
    "filters = all_filters\n",
    "\n",
    "for j in range(0, len(department_options)):\n",
    "    department = department_options[j]\n",
    "\n",
    "    ts.loads(url)\n",
    "    workbook = ts.getWorkbook()\n",
    "    worksheet = workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "    \n",
    "    filtered_workbook = worksheet.setFilter(\"DEPARTMENT\", department)\n",
    "    filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "    filters = filtered_worksheet.getFilters()\n",
    "    courses = filters[1][\"values\"]\n",
    "    course_progress_desc = f\"Progress through courses in {department}\"\n",
    "\n",
    "    overall_dataset = pd.DataFrame(columns=overall_columns)\n",
    "\n",
    "    for course in tqdm(courses, desc=course_progress_desc):\n",
    "        ts.loads(url)\n",
    "        workbook = ts.getWorkbook()\n",
    "        worksheet = workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "\n",
    "        filtered_workbook = worksheet.setFilter(\"DEPARTMENT\", department)\n",
    "        filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "        filtered_workbook = filtered_worksheet.setFilter(\"COMBINED_COURSE\", course)\n",
    "        filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "        filters = filtered_worksheet.getFilters()\n",
    "        professors =  filters[3][\"values\"]\n",
    "        for professor in professors:\n",
    "            ts.loads(url)\n",
    "            workbook = ts.getWorkbook()\n",
    "            worksheet = workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "\n",
    "            filtered_workbook = worksheet.setFilter(\"DEPARTMENT\", department)\n",
    "            filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "            filtered_workbook = filtered_worksheet.setFilter(\"COMBINED_COURSE\", course)\n",
    "            filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "            filtered_workbook = filtered_worksheet.setFilter(\"INSTRUCTOR_NAME\", professor)\n",
    "            filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "            filters = filtered_worksheet.getFilters()\n",
    "            terms =  filters[4][\"values\"]\n",
    "\n",
    "            for term in terms:\n",
    "                filtered_workbook = filtered_worksheet.setFilter(\"Term\", term)\n",
    "                filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "\n",
    "                try:\n",
    "                    current_data = filtered_worksheet.data[[\"University Core Questions-alias\", \"AVG(RESPONSE_VALUE)-alias\", \"CNT(RESPONSE_VALUE)-alias\"]]\n",
    "                    current_data.columns = [\"question\", \"rating\", \"percentage\"]\n",
    "\n",
    "                    current_data.insert(0, \"course_num\", [course] * len(current_data.index))\n",
    "                    current_data.insert(1, \"professor\", [professor] * len(current_data.index))\n",
    "                    current_data.insert(2, \"term\", [term] * len(current_data.index))\n",
    "                    question_numbers = []\n",
    "                    for i in range(0, len(current_data.index)):\n",
    "                        question_numbers.append(question_dict[current_data.loc[i, \"question\"]])\n",
    "                    \n",
    "                    current_data.insert(3, \"question_num\", question_numbers)\n",
    "\n",
    "                    current_data.drop(\"question\", axis=1, inplace=True)\n",
    "\n",
    "                    overall_dataset = pd.concat([overall_dataset, current_data])\n",
    "                except:\n",
    "                    print(f\"COULDN'T GET DATA FOR {course}, by {professor} during {term}\")\n",
    "\n",
    "    output_csv_filename = f\"full_scraped_evals_{j}.csv\"\n",
    "    overall_dataset.to_csv(output_csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Process data\n",
    "for i in range(0, 179):\n",
    "    input_csv_filename = f\"original/full_scraped_evals_{i}.csv\"\n",
    "    department_data = pd.read_csv(input_csv_filename)\n",
    "    department_data.drop(department_data.columns[[0]], axis = 1, inplace = True)\n",
    "    department_data.insert(0, \"department\", [i] * len(department_data.index))\n",
    "    output_csv_filename = f\"processed/full_scraped_evals_{i}.csv\"\n",
    "    department_data.to_csv(output_csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Concatenate all department csv files into one big one\n",
    "os.system(\"cat processed/full_scraped_evals*.csv > processed/combined_data.csv\")\n",
    "\n",
    "overall_dataset = pd.read_csv(\"processed/combined_data.csv\")\n",
    "\n",
    "# Drop indexing based on department, filter out all header columns that happen\n",
    "# in the middle of the data.\n",
    "overall_dataset.drop(overall_dataset.columns[[0]], axis=1, inplace=True)\n",
    "overall_dataset = overall_dataset[overall_dataset.department != \"department\"]\n",
    "\n",
    "# Convert \"Term\" strings to indices\n",
    "term_dict = {}\n",
    "for i in range(0, len(term_options)):\n",
    "    term_dict[term_options[i]] = i\n",
    "\n",
    "terms_list = []\n",
    "\n",
    "for term in overall_dataset[\"term\"]:\n",
    "    terms_list.append(term_dict[term])\n",
    "\n",
    "overall_dataset[\"term\"] = terms_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3243/338862513.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n",
      "/tmp/ipykernel_3243/338862513.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n",
      "/tmp/ipykernel_3243/338862513.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n",
      "/tmp/ipykernel_3243/338862513.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n",
      "/tmp/ipykernel_3243/338862513.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Combine all rows that are the same question (in progress)\n",
    "merged_dataset = overall_dataset.drop([\"rating\", \"percentage\"], axis=1)\n",
    "merged_dataset.drop_duplicates(inplace=True)\n",
    "\n",
    "current_rating_dataframe = pd.DataFrame()\n",
    "\n",
    "for i in range (1, 6):\n",
    "    current_rating_dataframe = overall_dataset[overall_dataset.rating == str(i)]\n",
    "    current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n",
    "    current_rating_dataframe.columns = ['department', 'course_num', 'professor', 'term', 'question_num', 'percentage_' + str(i)]\n",
    "    merged_dataset = pd.merge(merged_dataset, current_rating_dataframe, how=\"left\", on=[\"department\", \"course_num\", \"professor\", \"term\", \"question_num\"])\n",
    "\n",
    "merged_dataset.fillna(0, inplace=True)\n",
    "\n",
    "merged_dataset.to_csv(\"final_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
