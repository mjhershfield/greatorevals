{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GatorEvals Public Dataset!\n"
     ]
    }
   ],
   "source": [
    "from tableauscraper import TableauScraper as TS\n",
    "\n",
    "url = \"https://public.tableau.com/views/GatorEvalsFall2019toFall2021PublicData/GatorEvalsPublic\"\n",
    "\n",
    "ts = TS()\n",
    "ts.loads(url)\n",
    "workbook = ts.getWorkbook()\n",
    "\n",
    "worksheet = workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "data = worksheet.data\n",
    "head = data.head()\n",
    "\n",
    "print(\"Loaded GatorEvals Public Dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTER OPTIONS:\n",
      "---------------\n",
      "COLLEGE\n",
      "COMBINED_COURSE\n",
      "DEPARTMENT\n",
      "INSTRUCTOR_NAME\n",
      "Term\n"
     ]
    }
   ],
   "source": [
    "all_filters = worksheet.getFilters()\n",
    "college_options = all_filters[0][\"values\"]\n",
    "course_options = all_filters[1][\"values\"]\n",
    "department_options = all_filters[2][\"values\"]\n",
    "instructor_options = all_filters[3][\"values\"]\n",
    "term_options = all_filters[4][\"values\"]\n",
    "print(\"FILTER OPTIONS:\")\n",
    "print(\"---------------\")\n",
    "for f in all_filters:\n",
    "    print(f[\"column\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Takes about 30 hours to run ðŸ˜¬\n",
    "\n",
    "overall_columns = [\"course_num\", \"professor\", \"term\", \"question_num\", \"rating\", \"percentage\"]\n",
    "overall_dataset = pd.DataFrame(columns=overall_columns)\n",
    "\n",
    "question_texts = data[\"University Core Questions-value\"].truncate(0, 9).to_list()\n",
    "question_dict = {}\n",
    "for i in range(0, len(question_texts)):\n",
    "    question_dict[question_texts[i]] = i\n",
    "\n",
    "professor_list = []\n",
    "\n",
    "filters = all_filters\n",
    "\n",
    "for j in range(0, len(department_options)):\n",
    "    department = department_options[j]\n",
    "\n",
    "    ts.loads(url)\n",
    "    workbook = ts.getWorkbook()\n",
    "    worksheet = workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "    \n",
    "    filtered_workbook = worksheet.setFilter(\"DEPARTMENT\", department)\n",
    "    filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "    filters = filtered_worksheet.getFilters()\n",
    "    courses = filters[1][\"values\"]\n",
    "    course_progress_desc = f\"Progress through courses in {department}\"\n",
    "\n",
    "    overall_dataset = pd.DataFrame(columns=overall_columns)\n",
    "\n",
    "    for course in tqdm(courses, desc=course_progress_desc):\n",
    "        ts.loads(url)\n",
    "        workbook = ts.getWorkbook()\n",
    "        worksheet = workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "\n",
    "        filtered_workbook = worksheet.setFilter(\"DEPARTMENT\", department)\n",
    "        filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "        filtered_workbook = filtered_worksheet.setFilter(\"COMBINED_COURSE\", course)\n",
    "        filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "        filters = filtered_worksheet.getFilters()\n",
    "        professors =  filters[3][\"values\"]\n",
    "        for professor in professors:\n",
    "            ts.loads(url)\n",
    "            workbook = ts.getWorkbook()\n",
    "            worksheet = workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "\n",
    "            filtered_workbook = worksheet.setFilter(\"DEPARTMENT\", department)\n",
    "            filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "            filtered_workbook = filtered_worksheet.setFilter(\"COMBINED_COURSE\", course)\n",
    "            filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "            filtered_workbook = filtered_worksheet.setFilter(\"INSTRUCTOR_NAME\", professor)\n",
    "            filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "            filters = filtered_worksheet.getFilters()\n",
    "            terms =  filters[4][\"values\"]\n",
    "\n",
    "            for term in terms:\n",
    "                filtered_workbook = filtered_worksheet.setFilter(\"Term\", term)\n",
    "                filtered_worksheet = filtered_workbook.getWorksheet(\"GatorEvals Public Data\")\n",
    "\n",
    "                try:\n",
    "                    current_data = filtered_worksheet.data[[\"University Core Questions-alias\", \"AVG(RESPONSE_VALUE)-alias\", \"CNT(RESPONSE_VALUE)-alias\"]]\n",
    "                    current_data.columns = [\"question\", \"rating\", \"percentage\"]\n",
    "\n",
    "                    current_data.insert(0, \"course_num\", [course] * len(current_data.index))\n",
    "                    current_data.insert(1, \"professor\", [professor] * len(current_data.index))\n",
    "                    current_data.insert(2, \"term\", [term] * len(current_data.index))\n",
    "                    question_numbers = []\n",
    "                    for i in range(0, len(current_data.index)):\n",
    "                        question_numbers.append(question_dict[current_data.loc[i, \"question\"]])\n",
    "                    \n",
    "                    current_data.insert(3, \"question_num\", question_numbers)\n",
    "\n",
    "                    current_data.drop(\"question\", axis=1, inplace=True)\n",
    "\n",
    "                    overall_dataset = pd.concat([overall_dataset, current_data])\n",
    "                except:\n",
    "                    print(f\"COULDN'T GET DATA FOR {course}, by {professor} during {term}\")\n",
    "\n",
    "    output_csv_filename = f\"full_scraped_evals_{j}.csv\"\n",
    "    overall_dataset.to_csv(output_csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Process data\n",
    "for i in range(0, 179):\n",
    "    input_csv_filename = f\"original/full_scraped_evals_{i}.csv\"\n",
    "    department_data = pd.read_csv(input_csv_filename)\n",
    "    department_data.drop(department_data.columns[[0]], axis = 1, inplace = True)\n",
    "    department_data.insert(0, \"department\", [i] * len(department_data.index))\n",
    "    output_csv_filename = f\"processed/full_scraped_evals_{i}.csv\"\n",
    "    department_data.to_csv(output_csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Concatenate all department csv files into one big one\n",
    "os.system(\"cat processed/full_scraped_evals*.csv > processed/combined_data.csv\")\n",
    "\n",
    "overall_dataset = pd.read_csv(\"processed/combined_data.csv\")\n",
    "\n",
    "# Drop indexing based on department, filter out all header columns that happen\n",
    "# in the middle of the data.\n",
    "overall_dataset.drop(overall_dataset.columns[[0]], axis=1, inplace=True)\n",
    "overall_dataset = overall_dataset[overall_dataset.department != \"department\"]\n",
    "\n",
    "# Convert \"Term\" strings to indices\n",
    "term_dict = {}\n",
    "for i in range(0, len(term_options)):\n",
    "    term_dict[term_options[i]] = i\n",
    "\n",
    "terms_list = []\n",
    "\n",
    "for term in overall_dataset[\"term\"]:\n",
    "    terms_list.append(term_dict[term])\n",
    "\n",
    "overall_dataset[\"term\"] = terms_list\n",
    "\n",
    "# Convert \"Course\" strings to indices\n",
    "all_courses = overall_dataset[\"course_num\"]\n",
    "all_courses.drop_duplicates(keep=\"first\", inplace=True)\n",
    "all_courses.reset_index(drop=True, inplace=True)\n",
    "\n",
    "courses_dict = {}\n",
    "for i in range(0, len(all_courses.index)):\n",
    "    courses_dict[all_courses[i]] = i\n",
    "\n",
    "course_list = []\n",
    "\n",
    "for course in overall_dataset[\"course_num\"]:\n",
    "    course_list.append(courses_dict[course])\n",
    "\n",
    "overall_dataset[\"course_num\"] = course_list\n",
    "\n",
    "all_courses.to_json(\"courses_mappings.json\", orient=\"values\")\n",
    "\n",
    "# Convert \"Professor\" strings to indices\n",
    "all_professors = overall_dataset[\"professor\"]\n",
    "all_professors.drop_duplicates(keep=\"first\", inplace=True)\n",
    "all_professors.reset_index(drop=True, inplace=True)\n",
    "\n",
    "professors_dict = {}\n",
    "\n",
    "for i in range(0, len(all_professors.index)):\n",
    "    professors_dict[all_professors[i]] = i\n",
    "\n",
    "professors_list = []\n",
    "\n",
    "for professor in overall_dataset[\"professor\"]:\n",
    "    professors_list.append(professors_dict[professor])\n",
    "\n",
    "overall_dataset[\"professor\"] = professors_list\n",
    "\n",
    "all_professors.to_json(\"professor_mappings.json\", orient=\"values\")\n",
    "\n",
    "# Export Department Mappings\n",
    "department_mappings_json = json.dumps(department_options)\n",
    "with open(\"department_mappings.json\", \"w\") as department_mappings_file:\n",
    "    department_mappings_file.write(department_mappings_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_334/3290521355.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n",
      "/tmp/ipykernel_334/3290521355.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n",
      "/tmp/ipykernel_334/3290521355.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n",
      "/tmp/ipykernel_334/3290521355.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n",
      "/tmp/ipykernel_334/3290521355.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Combine all rows that are the same question\n",
    "merged_dataset = overall_dataset.drop([\"rating\", \"percentage\"], axis=1)\n",
    "merged_dataset.drop_duplicates(inplace=True)\n",
    "\n",
    "current_rating_dataframe = pd.DataFrame()\n",
    "\n",
    "for i in range (1, 6):\n",
    "    current_rating_dataframe = overall_dataset[overall_dataset.rating == str(i)]\n",
    "    current_rating_dataframe.drop(\"rating\", axis=1, inplace=True)\n",
    "    current_rating_dataframe.columns = ['department', 'course_num', 'professor', 'term', 'question_num', 'percentage_' + str(i)]\n",
    "    merged_dataset = pd.merge(merged_dataset, current_rating_dataframe, how=\"left\", on=[\"department\", \"course_num\", \"professor\", \"term\", \"question_num\"])\n",
    "\n",
    "merged_dataset.fillna(0, inplace=True)\n",
    "\n",
    "merged_dataset.to_csv(\"final_data.csv\")\n",
    "\n",
    "json_dataset = merged_dataset\n",
    "json_dataset.columns = ['d', 'c', 'p', 't', 'q', 'p1', 'p2', 'p3', 'p4','p5']\n",
    "\n",
    "dataset_types = {\"d\": int, \"c\": int, \"p\": int, \"t\": int, \"q\": int, \"p1\":float, \"p2\": float, \"p3\": float, \"p4\": float, \"p5\": float}\n",
    "json_dataset = json_dataset.astype(dataset_types)\n",
    "\n",
    "def round_to_4(x):\n",
    "    return round(x, 4)\n",
    "\n",
    "json_dataset[\"p1\"] = json_dataset[\"p1\"].apply(round_to_4)\n",
    "json_dataset[\"p2\"] = json_dataset[\"p2\"].apply(round_to_4)\n",
    "json_dataset[\"p3\"] = json_dataset[\"p3\"].apply(round_to_4)\n",
    "json_dataset[\"p4\"] = json_dataset[\"p4\"].apply(round_to_4)\n",
    "json_dataset[\"p5\"] = json_dataset[\"p5\"].apply(round_to_4)\n",
    "\n",
    "json_dataset.to_json(\"../public/final_data.json\", orient=\"records\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
